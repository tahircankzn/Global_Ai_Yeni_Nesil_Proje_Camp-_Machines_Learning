{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Seçilen Proje**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bu proje, insansız hava araçlarının (UAV'lerin) tespiti için bir sınıflandırma modeli geliştirmeyi amaçlamaktadır. Projede kullanılan veri seti, 33,100 adet UAV görüntü içeren kendi veri setimden seçilmiştir. UAV olmayan görüntüler, projenin gereksinimlerine uygun olarak özenle seçilmiş ve temsil edici bir veri seti elde etmek için kullanılmıştır.(UAV olmayan görüntü validasyon 151 ve train 377 ; UAV olan görüntü 177 validasyon  ve 1061 train)\n",
        "\n",
        "Modelin eğitiminde evrişimli sinir ağı (CNN) mimarisi tercih edilmiştir. CNN, görüntülerden özelliklerin çıkarılması ve sınıflandırma işleminin gerçekleştirilmesinde etkili bir yapısıyla öne çıkmaktadır. Geliştirilen model, eğitim verileri üzerinde başarılı bir şekilde eğitilmiş ve ardından doğrulama verileri üzerinde test edilmiştir.\n",
        "\n",
        "Veri seti oluşturma sürecinde, Savaşan İHA Yarışması için eğittiğimiz YOLO (You Only Look Once) modeline video verileri verilerek otomatik olarak veri seti oluşturulmuştur. Bu yöntem, geniş veri setleri gerektiren projelerde veri seti oluşturmayı kolaylaştırmış ve süreci hızlandırmıştır.\n",
        "\n",
        "Sonuç olarak, bu projenin amacı, UAV tespiti için etkili bir sınıflandırma modeli geliştirmektir. Ancak, temsili veri setinin yeterli kalitede olmamasından dolayı model yeterli başarıyı gösterememiştir. Gelecekteki çalışmalarda, modelin daha geniş ve daha temsilci veri setleri üzerinde test edilmesi ve performansının daha da iyileştirilmesi hedeflenmektedir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWP6pu4_4aB9"
      },
      "source": [
        "**Seçilen Yöntem**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UoKN-7E4aB-"
      },
      "source": [
        "Sınıflandırma projesi için UAV (Unmanned Aerial Vehicle - Insansız Hava Aracı) aracının resimde olup olmadığını tespit etmeyi amaçlayan bir projeyi seçtim.\n",
        "Bunun için görsel verilerde en çok tercih edilen yöntem olan CNN kullanmaya karar verdim.\n",
        "\n",
        "\n",
        "CNN'ler, özellikle görüntü işlemede başarılı olan bir yapay sinir ağı türüdür. Bu model, resimde uçak olup olmadığını belirlemek için eğitildi. Eğitim sırasında model, uçak içeren ve içermeyen resimler içeren bir veri kümesini kullanarak öğrendi. Model, resimlerdeki desenleri ve özellikleri tanımak için farklı evrişim katmanları ve havuzlama katmanlarından oluşur. Son olarak, model, resimdeki desenleri analiz ederek ve öğrendiği bilgileri kullanarak resmin uçak içerip içermediğini tahmin eder.\n",
        "\n",
        "1. Yüksek Başarı Oranı: CNN'ler, özellikle görüntü sınıflandırma gibi karmaşık görevlerde yüksek başarı oranları sağlar. Bu nedenle, uçak sınıflandırması gibi görüntü temelli bir sorun için en uygun seçenek olarak tercih edilmiştir.\n",
        "2. Özellik Çıkarma Yeteneği: CNN'ler, verilerdeki özellikleri otomatik olarak çıkarabilir. Bu özellik, el ile özellik mühendisliği yapmak zorunda kalmadan karmaşık görsel özellikleri tanımlamamıza olanak tanır.\n",
        "3. Ölçeklenebilirlik: CNN'ler genellikle büyük veri setlerinde iyi performans gösterir ve eğitilmesi ve kullanılması kolaydır.\n",
        "4. Uygunluk: Veri setinin yapısı ve problem alanının doğası, CNN'lerin kullanılmasını gerektirebilir. Örneğin, görüntü sınıflandırma problemleri, görüntüler arasındaki karmaşık ilişkileri tanımlamak için CNN'leri gerektirebilir.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br4iisVH5YtW"
      },
      "source": [
        "**CNN Nedir ?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY3eUXaw4aCA"
      },
      "source": [
        "CNN'ler, Evrişimli Sinir Ağları olarak da bilinir ve özellikle görüntü işleme alanında başarılıdır. Standart yapay sinir ağlarından farklı olarak, CNN'ler görüntü verilerini daha etkili bir şekilde işleyebilen özel bir mimariye sahiptir.\n",
        "\n",
        "CNN'lerin temel yapı taşı \"evrişim\" (convolution) katmanıdır. Bu katman, girdi görüntü üzerinde belirli bir filtre matrisini kaydırarak (convolution işlemi) girdi verisinden özellik haritaları çıkarır. Bu sayede, görüntünün çeşitli özellikleri (kenarlar, köşeler, desenler vb.) fark edilir.\n",
        "\n",
        "Ardından, \"havuzlama\" (pooling) katmanı gelir. Bu katman, özellik haritalarını küçültür ve önemli özellikleri vurgular. Bu işlem, ağın daha hızlı öğrenmesini ve daha az hesaplama yapmasını sağlar.\n",
        "\n",
        "CNN'ler genellikle bu evrişim ve havuzlama katmanlarının tekrarı ile oluşturulur. Daha sonra, tam bağlantılı (fully connected) katmanlar gelir. Bu katmanlar, özellikleri sınıflara (uçak, araba, vb.) karşılık gelen çıktılarla ilişkilendirir. Eğitim sırasında, ağ, doğru sınıflandırmayı yapabilmek için girdi verileriyle ağırlıklarını ayarlar.\n",
        "\n",
        "Sonuç olarak, CNN'ler, görüntü verilerinden özellikleri çıkararak ve bu özellikleri kullanarak sınıflandırma yapabilen güçlü ve etkili sinir ağı modelleridir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWEzg-eW58JQ"
      },
      "source": [
        "**Projede Kullanacağım Derin Öğrenme Kütüphanesi PYTORCH'un Eklenmesi**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Sslbv4qa4aCB"
      },
      "outputs": [],
      "source": [
        "import torch.optim as opt\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40ElUAxh53RN"
      },
      "source": [
        "# **MODELİN OLUŞTURULMASI VE EĞİTİME HAZIRLIK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzwu9Rxgvc3_"
      },
      "source": [
        "**MODEL GÖRSELİ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxJYRrFf4aCA"
      },
      "source": [
        "<img src=\"model.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ0sITeyulST"
      },
      "source": [
        "**Model Katman Çıktıları :**\n",
        "* conv1: 1 kanal girişi (grayscale), 30 filtre, çekirdek boyutu 7x7, adım (stride) 2, dolgu (padding) 3 kullanılarak hesaplanır. Bu durumda çıktı boyutu şöyle olur: 64 (batch size) x 30 (filtre sayısı) x 112 x 112.\n",
        "* pool1: Max pooling işlemi uygulandığında, çıktı boyutu 64 x 30 x 55 x 55 olur.\n",
        "* conv2: 30 kanal girişi, 60 filtre, çekirdek boyutu 1x1, adım 2 kullanılarak hesaplanır. Bu durumda çıktı boyutu şöyle olur: 64 x 60 x 28 x 28.\n",
        "* pool2: Max pooling işlemi uygulandığında, çıktı boyutu 64 x 60 x 14 x 14 olur.\n",
        "* conv3: 60 kanal girişi, 120 filtre, çekirdek boyutu 1x1 kullanılarak hesaplanır. Bu durumda çıktı boyutu şöyle olur: 64 x 120 x 14 x 14.\n",
        "* pool3: Max pooling işlemi uygulandığında, çıktı boyutu 64 x 120 x 7 x 7 olur.\n",
        "* conv4: 120 kanal girişi, 240 filtre, çekirdek boyutu 1x1 kullanılarak hesaplanır. Bu durumda çıktı boyutu şöyle olur: 64 x 240 x 7 x 7.\n",
        "* fc1: Tam bağlı (fully connected) katman, 11760 boyutunda bir girişi alır ve 5000 boyutunda bir çıktı üretir.\n",
        "* fc2: 5000 boyutundaki girişi alır ve 1000 boyutunda bir çıktı üretir.\n",
        "* fc3: 1000 boyutundaki girişi alır ve 500 boyutunda bir çıktı üretir.\n",
        "* fc4: 500 boyutundaki girişi alır ve 250 boyutunda bir çıktı üretir.\n",
        "* fc5: 250 boyutundaki girişi alır ve 5 boyutunda bir çıktı üretir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Twz-3Imm4aCC"
      },
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1,30,kernel_size=7,stride=2,padding=3) \n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=3,stride=2)\n",
        "\n",
        "        # transition layer 1 ->\n",
        "        self.conv2 = nn.Conv2d(30,60,kernel_size=1,stride=2) \n",
        "        self.bn2 = nn.BatchNorm2d(60)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "\n",
        "        # transition layer 2 ->\n",
        "        self.conv3 = nn.Conv2d(60,120,kernel_size=1)\n",
        "        self.bn3 = nn.BatchNorm2d(120)\n",
        "        self.conv3_drop = nn.Dropout2d()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "        # transition layer 3 ->\n",
        "        self.conv4 = nn.Conv2d(120,240,kernel_size=1)\n",
        "        self.bn4 = nn.BatchNorm2d(240)\n",
        "        self.conv4_drop = nn.Dropout2d()\n",
        "        \n",
        "\n",
        "        # classification layer->\n",
        "        self.fc1 = nn.Linear(11760, 5000)\n",
        "        self.fcDout = nn.Dropout()\n",
        "        self.fc2 = nn.Linear(5000, 1000)\n",
        "\n",
        "        self.fc3 = nn.Linear(1000, 500)\n",
        "\n",
        "        self.fc4 = nn.Linear(500, 250)\n",
        "        self.fc5 = nn.Linear(250, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # starting layer ->\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        # transition layer 1 ->\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.conv2_drop(x)\n",
        "        x = self.pool2(x)\n",
        "        x = torch.relu(x)  \n",
        "\n",
        "        # transition layer 2 ->\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.conv3_drop(x)\n",
        "        x = self.pool3(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        # transition layer 3 ->\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.conv4_drop(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x = x.view(-1, 11760) \n",
        "\n",
        "        # Lineer katmanların çıkışını hesapla\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fcDout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fcDout(x)\n",
        "        x = self.fc3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fcDout(x)\n",
        "        x = self.fc4(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fcDout(x)\n",
        "        x = self.fc5(x)\n",
        "\n",
        "\n",
        "        return torch.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFVJswwv6MfA"
      },
      "source": [
        "**VERİ SETİMİZİN PYTHORCH İÇİN TENSÖR HALİNE GETİRİLMESİ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6akdH0oC4aCE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "class data(Dataset):\n",
        "    def __init__(self,dataset):\n",
        "\n",
        "        data = np.loadtxt(f'{dataset}.csv', delimiter=',')\n",
        "        self.veriler = data[:, 2:]\n",
        "        self.hedefler = data[:, 0:2]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.veriler)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "    \n",
        "        veri = torch.tensor(self.veriler[idx].reshape(-1, 240, 240)).float()\n",
        "        hedef = torch.tensor(self.hedefler[idx]).float()\n",
        "\n",
        "\n",
        "        return veri, hedef"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IllDwx5m7_1w"
      },
      "source": [
        "**EĞİTİM PARAMETRELERİ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dMsqyst8eBr"
      },
      "source": [
        "\n",
        "\n",
        "* **MOMENTUM** : SGD optimizasyon algoritmasının güncelleme adımlarında ne kadar\n",
        "geçmiş gradyan bilgisini kullanacağını kontrol eden bir parametredir. Yüksek momentum değerleri, daha fazla geçmiş gradyan bilgisini kullanır ve bu da optimizasyon sürecinde daha az salınım ve daha düzgün bir güncelleme yolu sağlayabilir\n",
        "* **EPOCHS** : Modelin tüm veri kümesi üzerinde kaç kez eğitileceğini belirten epoch sayısı\n",
        "* **Batch Size** : Test verilerinin kaçarlık gruplar halinde kullanılacağını belirten batch boyutu\n",
        "* **Learning Rate** : Öğrenme oranı\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "85cBHVU_4aCE"
      },
      "outputs": [],
      "source": [
        "n_epochs = 40  \n",
        "batchSizeTrain = 128  \n",
        "batchSizeTest = 128\n",
        "learning_rate = 0.001 \n",
        "momentum = 0.99"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7ZV5x0L9dLX"
      },
      "source": [
        "**MODELİN EĞİTİM SIRASINDA GÖSTERDİĞİ HATA VE BAŞARI MİKTARLARININ GRAFİKLEŞTİRİLMESİ İÇİN LİSTELER OLUŞTURULDU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "X2AuqISr4aCF"
      },
      "outputs": [],
      "source": [
        "lossL = []\n",
        "train_Accuracy = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOCtwQhF-Wmz"
      },
      "source": [
        "**MODELİN EĞİTİLECEĞİ BİRİM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JYsMmL--I5f"
      },
      "source": [
        "EĞİTİMİ CPU YADA GPU (CUDA) İLE EĞİTEBİLİRİZ\n",
        "EĞİTİM SIRASINDA CUDA KULLANILMASI İŞLEMLERİN EKRAN KARTININ İŞLEM GÜÇÜNDEN FAYDALANARAK İŞLEMLERİN HIZLANMASINI SAĞLAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "kkjH6Jce65lH"
      },
      "outputs": [],
      "source": [
        "device = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "b5CMyRhy67hl"
      },
      "outputs": [],
      "source": [
        "trainLoader = DataLoader(data(\"__dataset__\"), batch_size=batchSizeTrain, shuffle=True)\n",
        "\n",
        "testLoader = DataLoader(data(\"__dataset_valid__\"), batch_size=batchSizeTrain, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBlFj_Nz-dyJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-gTwg66q7AHe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (conv1): Conv2d(1, 30, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
            "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(30, 60, kernel_size=(1, 1), stride=(2, 2))\n",
            "  (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(60, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (bn3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3_drop): Dropout2d(p=0.5, inplace=False)\n",
            "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv2d(120, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (bn4): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4_drop): Dropout2d(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=11760, out_features=5000, bias=True)\n",
            "  (fcDout): Dropout(p=0.5, inplace=False)\n",
            "  (fc2): Linear(in_features=5000, out_features=1000, bias=True)\n",
            "  (fc3): Linear(in_features=1000, out_features=500, bias=True)\n",
            "  (fc4): Linear(in_features=500, out_features=250, bias=True)\n",
            "  (fc5): Linear(in_features=250, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "myModel=Network().to(device)\n",
        "print(myModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5y__cYK-jg9"
      },
      "source": [
        "**OPTİMİZER NEDİR ?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rqwVi-lt9qr"
      },
      "source": [
        "Optimizer, bir makine öğrenimi modelinin eğitim sürecinde kullanılan bir algoritmadır. Bu algoritma, modelin ağırlıklarını güncellemek için kullanılır ve kayıp fonksiyonunu minimize ederek modelin doğru sonuçları üretmesini sağlar. Optimizasyon algoritmaları, öğrenme oranı, momentum ve düzenleme gibi teknikleri kullanarak modelin daha hızlı öğrenmesini, aşırı uyumu azaltmasını ve daha iyi genelleme yapmasını sağlar. Doğru optimizer seçimi, modelin daha iyi performans göstermesini ve daha iyi sonuçlar elde etmesini sağlayabilir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S07UGjDruDaj"
      },
      "source": [
        "**Stokastik gradyan iniş (SGD) Seçilme Sebebi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNzfNNq6-rKi"
      },
      "source": [
        "* Hızlı Öğrenme: Momentum, gradyan inişindeki dalgalanmaları azaltarak daha hızlı bir öğrenme sağlayabilir. Bu, konverjansı hızlandırabilir ve eğitim süresini kısaltabilir.\n",
        "*Daha İyi Genelleme: Momentum, ağırlık güncellemelerini daha düzenli hale getirerek aşırı uyumu (overfitting) azaltabilir. Bu, modelin genel olarak daha iyi performans göstermesini sağlayabilir.\n",
        "*Daha İyi Minimumlar: Momentum, yerel minimumlere sıkışmadan önce daha geniş alanları keşfetmeye yardımcı olabilir. Bu, modelin daha iyi, daha geniş minimumlara ulaşmasını sağlayabilir.\n",
        "*Daha İyi Gradient Descent Performansı: Momentum, gradient desent sırasında yakalanabilecek yerel optimumlere karşı daha dirençli bir yapı oluşturabilir.\n",
        "*Parametrelerin Daha İyi Ayarlanması: Momentum, öğrenme oranını daha etkili bir şekilde ayarlamanıza olanak tanır. Bu, öğrenme sürecini daha verimli hale getirebilir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "XQuZWgRt7Eyo"
      },
      "outputs": [],
      "source": [
        "optimizer = opt.SGD(myModel.parameters(), lr=learning_rate, momentum=momentum) # ağırlık güncellemesi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7h3-RfP-vh3"
      },
      "source": [
        "# **EĞİTİM AŞAMASI**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "pJdL6EHx7KNZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Network(\n",
              "  (conv1): Conv2d(1, 30, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(30, 60, kernel_size=(1, 1), stride=(2, 2))\n",
              "  (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(60, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (bn3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3_drop): Dropout2d(p=0.5, inplace=False)\n",
              "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv4): Conv2d(120, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (bn4): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4_drop): Dropout2d(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=11760, out_features=5000, bias=True)\n",
              "  (fcDout): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=5000, out_features=1000, bias=True)\n",
              "  (fc3): Linear(in_features=1000, out_features=500, bias=True)\n",
              "  (fc4): Linear(in_features=500, out_features=250, bias=True)\n",
              "  (fc5): Linear(in_features=250, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "myModel.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "g7-K9zsk7M5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n"
          ]
        }
      ],
      "source": [
        "for e in range(n_epochs):\n",
        "    print(e+1)\n",
        "    for batch,target in trainLoader:\n",
        "    \n",
        "        optimizer.zero_grad() #Gradientleri sıfırla\n",
        "        o=myModel.forward(batch.to(device))\n",
        "        \n",
        "        loss = F.cross_entropy(o, torch.argmax(target, dim=1).to(device))# cross entropy çok boyutlu targetlarda kullanılır\n",
        "        loss.backward()\n",
        "        optimizer.step() # ağırlık güncellemesi\n",
        "        lossL.append(loss)\n",
        "    correct = 0\n",
        "    for batch,target in testLoader:\n",
        "\n",
        "            o=myModel.forward(batch.to(device))\n",
        "\n",
        "            pred = o.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            correct += pred.eq(torch.argmax(target, dim=1).to(device).data.view_as(pred)).sum()\n",
        "\n",
        "    train_Accuracy.append(correct)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCyztwsj-7nQ"
      },
      "source": [
        "**VALİDASYON VERİ SETİ EĞİTİLMİŞ VERİ SETİNE VERİLİR VE BAŞARI YÜZDESİ GÖSTERİLİR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "cwQjWOrD7Nik"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Accuracy: 165/328 (50%) - lr : 0.001\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Test\n",
        "myModel.eval()\n",
        "testLoss = 0\n",
        "correct = 0\n",
        "for batch,target in testLoader:\n",
        "        o=myModel.forward(batch.to(device))\n",
        "        pred = o.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(torch.argmax(target, dim=1).to(device).data.view_as(pred)).sum()\n",
        "testLoss /= len(testLoader.dataset)\n",
        "print('\\nTest set: Accuracy: {}/{} ({:.0f}%) - lr : {}\\n'.format(\n",
        "    correct, len(testLoader.dataset),\n",
        "    100. * correct / len(testLoader.dataset),learning_rate))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zGetYpI_UDq"
      },
      "source": [
        "**EĞİTİM AŞAMASINDAKİ HATA VE BAŞARI GRAFİKLERİ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "8_ZFsGyt7cE_"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()\n",
        "for n_iter in range(len(train_Accuracy)):\n",
        "\n",
        "    writer.add_scalar('Accuracy/train', train_Accuracy[n_iter], n_iter)\n",
        "\n",
        "for n_iter in range(len(lossL)):\n",
        "\n",
        "    writer.add_scalar('Loss/train', lossL[n_iter], n_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"Ekran Alıntısı.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"Ekran Alıntısı2.png\">"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
